# for install hadoop cluster 
# version 1.0
# zhenglei
# 619366205@qq.com

# all host node's server name
all_host:master01,slave01,slave02,slave03
# namenode
nn_host:master01
# secondary namenode
snn_host:master01
# datanode 
dn_host:slave01,slave02,slave03
# mapreduce history host
mr_his_host:master01

# resource manager
rm_host:master01
# node manager
nm_host:slave01,slave02,slave03

# yarn proxy host
yarn_proxy_host:master01


# install detail path
# namenode dir
NN_DATA_DIR:/var/data/hadoop/hdfs/nn
# secondary namenode dir
SNN_DATA_DIR:/var/data/hadoop/hdfs/snn
# datanode dir
DN_DATA_DIR:/var/data/hadoop/hdfs/dn
# yarn user log dir
YARN_LOG_DIR:/var/log/hadoop/yarn
# hadoop user log dir
HADOOP_LOG_DIR:/var/log/hadoop/hdfs
# mapreduce user log dir
HADOOP_MAPRED_LOG_DIR:/var/log/hadoop/mapred
# yarn pid dir
YARN_PID_DIR:/var/run/hadoop/yarn
# hadoop pid dir
HADOOP_PID_DIR:/var/run/hadoop/hdfs
# mapreduce pid dir
HADOOP_MAPRED_PID_DIR:/var/run/hadoop/mapred
# 
HTTP_STATIC_USER:hdfs
# default yarn proxy port
YARN_PROXY_PORT:8081


###############################################################
# add users and groups
# groups
GROUP_HADOOP:hadoop
# users
USER_YARN:yarn
USER_HDFS:hdfs
USER_MAPRED:mapred


###############################################################
# software path
SOFTWARE_PATH:/home/blueseyes1021/documents/hadoop_software/
# install path
INSTALL_PATH:/opt/
# profile.d
PROFILED:/etc/profile.d/
# software package name
# you can replace with your package name
HADOOP_PKG:hadoop-2.7.3.tar.gz
JAVA_PKG:jdk1.8.0_92.tar.gz
SPARK_PKG:spark-2.0.1-bin-hadoop2.7.tgz
SCALA_PKG:scala-2.11.8.tgz
HIVE_PKG:apache-hive-1.2.1-bin.tar.gz
#KAFKA_PKG:kafka_2.11-0.10.1.1.tgz
#HBASE_PKG:
MAVEN_PKG:apache-maven-3.3.9.tar.gz

###############################################################
# default install
# link home
LINK_HOME:/usr/mylink/
# software home
HADOOP_HOME:hadoop
JAVA_HOME:java
SPARK_HOME:spark
SCALA_HOME:scala
HIVE_HOME:hive
KAFKA_HOME:kafka
MAVEN_HOME:maven
# xml_config.json
HADOOP_JSON:configuration.json
# hadoop etc path
HADOOP_ETC:/usr/mylink/hadoop/etc/hadoop/
# spark conf path
SPARK_CONF:/usr/mylink/spark/conf



###############################################################
# others
PORT:22
USER:root
PASSWD:
